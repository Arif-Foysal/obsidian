#FYDP #project 


>[!Ideas]
>- Suggesting the most likely condition, with the other conditions that also might occur to the patient.


## Speech

Good afternoon everyone, today we are going to present our project idea which is **Computer Vision Based Medical Diagnosis System** designed to assist doctors in detecting and diagnosing diseases more accurately and efficiently.

Before we dive into the details, Take a look at this X-ray. At first glance, it might look normal, right? But what if I told you there’s actually a fracture somewhere in this image? 


Well the fracture is highlighted by the pink box right over here. See this is a child’s hand, and children’s bones are more malleable than adult bones. So, when they break their wrist, it’s often a bend or a dent rather than a clean fracture/break.

Now, obviously we are not medical professionals here, but even well-trained doctors can sometimes miss it. In fact, studies show that radiologists can miss up to **20-30% of abnormalities**in medical images due to the sheer volume of cases, fatigue, or the subtlety of certain conditions.


Our goal is to build an AI powered application that uses **deep learning** and **computer vision** that will learn from medical data such as x-ray, blood tests and even skin images and provide **highly informed desicions** about their diagnosis, their treatment options, prognosis and so on. 


## Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/3PbEgLw6lJ0?si=BkUuyWVFoZmiqkcz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Transcript

we're in the middle of a healthare crisis doctors and nurses are burning out waiting times keep getting longer and longer and we Face new challenges such as antibiotic resistance and new viruses you might have heard of AI as this magical tool that's changing technology and you might have thought about Ai and Healthcare and whether there's some applications uh so I'm going to show you a few applications and why I'm really excited about this now you might have already interacted with AI in some way maybe with Siri Google Alexa smart devices or maybe you've seen or been in an autonomous car cool uh or maybe you just wash Terminator and you think we should burn all this AI business to the ground so maybe we should start asking ourselves what is AI and why should we use it in healthcare no what is AI so we first start with data and data can come in the form of text such as medical record x-ray scans such as images and just data in the form of whatever uh sound stock market all of this data gets analyzed by this AI system which is just a pattern recognition tool we're just looking at the data and seeing what's in there the system under goes a process called training essentially what happens is that the model gets better and better and better at identifying these p patterns now you will see that it never actually reaches 100% And if it does in my experience there's usually something wrong with it so once you have a trained AI system you hope to have something we call generalization generalization is when you have new data coming in and your AI system is able to identify the same patterns for example if a new patient comes in your hospital and you get a chest x-ray then you're able to understand whether the patient has cancer or not or maybe Elon Musk goes on a Twitter run page and we can predict that the stock market uh price of Tesla is going to go down and finally search engines you probably have interacted with search engines that identify the the websites uh that you're most interested in this is all cool we can see how AI can be used in Tech now how about AI in healthcare and why should we use it the short answer here is to help doctors and nurses and I have an example for this pajama time now for most of us pajama time literally just means to get ready for sleep unfortunately this is not the case for doctors for doctors pajama time means completing the tasks that they couldn't do during the day and this includes um medical records maintaining them um doing bureaucratic work for the hospital or simply keep up with the research and it's no wonder that actually two3 of doctors mentioned burnout as the main C cause of distress now there are two main causes of burnout for doctors one is paperwork two under Staffing let's start with paperwork as I said there's a lot of paperwork involved when you have patients you need to make sure that you take notes when the patient is telling you something important and you need to make sure that you are listening and the second one is under Staffing and for this I have an example about Job vacancies now the data is only for England unfortunately I couldn't not find the data for Scotland now we have job vacancies for doctors so for every 20 doctors only 19 of them are filled so that means that there's one doctor job vacancy that that the that is redistributed across the 19 of the doctors if you thought that was bad nurses for every job uh every 10 job vacancies for nurses only nine of them are filled that means that the work of that one nurse is spread Ross the nine nurses and this is just the tip of the iceberg now let's look at waiting times again NHS England sorry Scottish people in the audience um you can see the this is the number of patients on the y axis for the last um I don't know how many years essentially it goes up and it goes up to a point um where we're getting close to 8 million people and this has gotten worse especially after Co now for your context there are 50 million people in England 5 so that means there's about one in five people that are waiting to see a doctor this is insane and we have an aging population so this is only going to get worse so how can AI help essentially you might have heard of this um chat but really cool guys that was not even a joke you might have heard of chat GPT now he a good friend of mine uh if you don't know what it is is a smart chat but you can ask it questions it will reply um hopefully with the right answer um but you can ask it to do various things like coding you can help it write um you can help it ident can help you identify new scientific papers now I thought it'd be cool for Chad GPT to say hi to all of you before we start talking about it and I believe this is the first time in tedex history that this happened so yeah so I think there are three main ways Chad GPT can help or technology thereof one is for Preparation so before you go into a meeting with a patient CH GPT analyzes all the health records and tells you well you should follow up on these specific things second one is logging and here I mean logging in the health record so while you are with a patient uh we want the doctors to spend as much time with a patient as possible we don't want them to be taking notes uh we want them to to feel heard so one way we can do this is to automatically record a conversation and then have a system that summarizes the main points of the conversation and the third one is research as I said is extremely hard keeping up with the research it is for me and even harder for doctors the cool thing about Chad GPT is that it interacts with us with language so if there's a new symptom that comes up in the patient record it can identify new scientific research that shows maybe new diseases correlated with that symptom so we talked about language now let's talk about images this is an MRI scan and actually this is work that I was involved in so when you get an MRI scan you get into this machine and you're you should be very very still you're um because if you move even slightly your scan will be blurred like the one over there now you can't do much with a blurred scan so the doctor can either try their best to identify patterns whether you have brain cancer or anything or you will need to do it again now this is extremely uncomfortable as I said so what we did is we took low resolution scans brain Andi scans and we took high resolution ones and we taught an AI system to automatically increase the resolution of these scans and now from this scan what you can get is something like this now this you can get it with the computational power of your phone so it's very fast it's very easy to run and saves you time uh saves doctor's time saves patient time very cool my final example is Retina scans essentially when you go to an optometrist they look at the back of your eye and see if there's anything wrong now if there is anything wrong they will refer you for a surgery and they will also attach an urgency to that surgery what Google Deep Mind did is based on the scans identify whether the patient needed to be seen urgently or Not by a healthcare professional and now I have the data over here this is the error rate on the referral decision you have optometrist retina specialist and AI now you can see that thei matches more or less the the performance of the the the healthcare Specialists.


so this is very cool because again these models run really quickly and can be deployed in areas where there just aren't that many doctors you can use them to pre-screen the population so that these high at risk people can be seen by by the doctors now it's important here I'm not saying we should replace doctors we should help them you might have noticed that uh the error rate was never actually 0% and I mentioned this is a problem in AI so we should think about what happens when it makes mistakes now I have prepared a five point non-exhaustive list of what happens like the problems that we might face and ways we can mitigate them so the first one is bias we don't want the bias in society to be um spread around um so one way we can do this is make sure that the populations in the data are well represented and we can do audits so different companies can check that the models are that the models that are deployed are working well the second one is transparency and now this is a really hard one because it's really hard to open up the AI system and understand why they made a specific decision and I think here the only real solution is to look at the open source code now open source code means that you and me can access the code for free and understand what happens under the hood privacy of course we want our data to be private so it needs to be encrypted and we want data minimization so we don't need to collect all the data we possi can about a patient we just need the data that we need accountability so when it makes mistakes there should be a person or an institution that's responsible for those mistakes and there should be user feedback so if the AI makes mistakes we should learn from them and finally safety of course we want something safe to be deployed especially in healthcare so one problem here is called hallucination uh espe especially if you used TBT before you can see that it confidently tells you something even though it's false and you can argue with it and it's like no no no it's false and continues so it it is a big problem so we need to make sure that when these models are deployed they're fully analyzed and there should be fallback strategies so if the AI system fails there should be a human taking over the AI now this is all cool I talked about Ai and all the possible applications now like to talk about the next Frontier and the next Frontier is proteins that was a joke um it's actually my PhD project so you might think of proteins as the the things that you eat before you go to the gym but actually proteins do pretty much everything in the natural world you can think of them as Legos now as a kid I used to love Legos because oh yeah because as long as you have these instructions then you can build your own spaceship or uh whatever it's very cool and much like that proteins are made of these building blocks called amino acids and you can put them in Chains and when you do you create these proteins I like to call proteins The Architects of life on Earth because as I said they do pretty much everything I'm going to show you a few examples of this you'll know plants plants do photosynthesis so this big guy over here is rubisco it helps with photosynthesis it's one of my favorite proteins um this is DNA DNA needs to be replicated and to replicate DNA we use DNA polymerase over there so what I'm trying to say here is that as long as you have instructions which come in the form of DNA you have your building blocks which are amino acids then you can build your your spaceship or a protein now as my final example I have this thing that you should be familiar with covid-19 this thing sticking out you guessed it it's a protein it's called a spike protein and you might be also familiar with this other protein called an antibody now what happens with antibodies is that they attach to the spike protein and they initiate an immune response now to do this we actually need to create lots of different random shaped antibodies until we find the correct one matches the shape of the co and we initiate the immune response this takes time a long time which is why it takes us time to heal up from diseases now believe it or not this is actually a similar approach that the pharmaceutical industry uses in finding new cures essentially they have lots of compounds and they dump them all at the problem and try to see which compound actually decreases the um the side effects or cures the disease and this is really time consuming so what I'm proposing here is to use a Ai and I have a an example with Co so if you have a spike protein like the one I showed you earlier you can ask an AI to dream up the shape on an antibody or like the most probable shape on an antibody that will bind Co and now you can ask it to design based on that shape the actual antibody so there we have it instantly we generated a new antibody that we know will bind Co and the cool thing about this is that if we have new viruses coming up then we can instantly generate new antibodies for those viruses as well cool now much like any new technology we need to be careful we need to make sure that we know how to use AI before we deploy it but I believe that once we'll be able to do that it will change the world thank you




## Video
<iframe width="560" height="315" src="https://www.youtube.com/embed/Et5HC8SR0BA?si=__-vSN0V_W15GHkL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
Transcriber: Elisabeth Buffard
Reviewer: Anna Sobota Take a look at this x-ray here. I’m going to give you a medical pop quiz. Does anything look out of place 
with this x-ray that you can see? What if I told you there was actually
a fracture somewhere in this x-ray? Would you believe me? Well, it turns out that is the case
as shown by this pink box here. That little crinkle there that you see is actually what’s called
a Taurus fracture. See, this is a child’s hand, this x-ray, and children’s bones are more malleable than adult bones. So sometimes when they break their wrist, it’s more of a dent or a bend 
than it is an actual clean break. Now, you might not know 
to look for things like this, but I only happen to know 
because I went to medical school. I’m the person that built this AI. My name is Logan Nye, I am  a research physician
at Harvard Medical School, where I develop 
intelligent systems for health care or in other words, 
I’m a physician who codes. And that makes me unique 
and in a couple of ways. One, it makes it so that I’m probably the biggest nerd
that you’ve ever met in your life. That’s quite the overlap. But also it gives me
a unique vantage point for creating artificial intelligence
for medical diagnostics and health care. Usually when you develop 
artificial intelligence, you have developers and you have 
domain experts and there’s some crosstalk and they develop these
sorts of algorithms. But I want to show you some insights
as to why it’s helped me to be someone
with scientific domain knowledge that just learns how to develop 
artificial intelligence directly. So to do so, I’m going to share 
but not just any cartilage tissue. They’re both tumors. On the left we have enchondroma,
which is a benign condition. It’s just a clump of cells that you don’t need 
any particular medical care for. You just keep an eye on it
for the rest of your life. But on the right-hand side, 
we have low-grade chondrosarcoma. It looks almost identical, but it’s vastly different results. Low-grade chondrosarcoma
is very aggressive and needs to be treated aggressively. It requires surgery, often amputation and cautery of the wound
that you scrape out. So obviously, it's important to know
the difference between these two. But historically, we’ve been about 50% reliable
in telling them apart on histology. I know about this because I’m in medicine and it’s a widely known problem. But as I also happen to know how to build
artificial intelligence systems, I realize that this is great
for image classification, a computer vision problem. And so over the course of an afternoon, we built a computer vision program that took our diagnostic accuracy
between these two different tumor types from around 50% to 75 to 90%. It was a long-standing problem
for several decades but if we apply AI and know
how to apply it in a clinical context, we can solve those long-standing problems
in a short course of time. And there’s other applications as well. Take these knee MRIs. These are showing different ACLs
or anterior cruciate ligament that get torn. Using computer vision, we can automatically find 
where and when they’re torn. On the left-hand side
we have a healthy ACL, in the middle
a completely ruptured ACL, on the right the AI systems
that we develop are able to tell that
it’s only partially torn. This is another way that computer vision
can be applied within health care. That’s just the tip of the iceberg. We have scaphoid fractures. We’re able to detect lumbar disc 
herniations when people have back pain and need to localize where their nervous
system is being pressed on. We’re able to get fractures in arm areas, foot and ankle, hips, and we’re even able to quantify
osteoarthritis in knees to tell people when they should
be considering getting a knee replacement. All this is possible because we apply
artificial intelligence from a clinical standpoint. In our lab, we’ve also worked
on cancer diagnostic systems similar to the enchondroma problem, but applied to over 30 different 
other soft tissue tumors. And not just soft tissues,
but 15 or more bone tumors as well. We’re continuing to expand experiment
with these different applications in the clinical context. Again made possible
because we know what to look for and thus how to build AI. And in some cases,
when you have rare diseases, you lack the data to create these useful artificial
intelligence programs. Enchondroma is an example of this,
that first tumor that we looked at. But thanks to generative AI,
we can bridge that gap and the scarcity
of medical data that exists. This histology image of enchondroma
actually doesn’t exist. It was generated by AI, but because we know that
that’s a gap that exists in clinical care, we can leverage AI to fill those needs. Now, you might ask why is this important? I can tell you why
it’s personally important and why I became interested 
in developing artificial intelligence. During medical school,
I had the opportunity to participate in global health trips. One of them was to sub-Saharan Africa. The people there are incredible
and do awesome things with what they have, but there’s no denying
that they lack resources. We drived all the way out into the bush and we would spend all day working with the types of supplies that you’d find
at OfficeMax or Home Depot to care for patients. But one thing that I noticed was that the medical staff used iPads 
to record all their patient data. They had access to smartphones. And again, when I went to the Himalayas, we treated all sorts of patients
in far reaches across the Himalayan mountain range and they lacked those resources,
but they all had smartphones. So anybody that has a smartphone is able to access
artificial intelligence systems and thus get proper care. And so that’s what we’re working on. We’re working on apps and APIs that we can open source,
make available to anybody anywhere. If you have Internet access
and if you have a smart device, we can democratize our medical expertise
to those who most need it. Preventing the need to travel 
for days or even weeks to get the care that they need. And so, I would encourage
other people that are domain experts, whether it be in medicine,
law, education, whatever, to try to find ways
to use artificial intelligence to amplify your expertise 
and make it available to other people. Who knows, it might just save lives. Thank you. (Applause).

## video
<iframe width="560" height="315" src="https://www.youtube.com/embed/uvqDTbusdUU?si=3rgDsbtTbN__Kjwc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#### **Transcript:**
 Artificial intelligence has often been depicted as villain robots ready to take over the world.  
But I’m here to tell you that AI can actually save lives and improve health care for millions of patients around the world.  
AI is helping us personalize the delivery of care, make hospitals more efficient, and improve access to health care by providing accurate decision-making tools.  
AI is the process of educating a computer model using complex and large data sets.  
The model learns from this data in a training process to build its ability to make decisions or predict outcomes when presented with new data.  
We are talking about having access to a computer model that knows, based on the experience of thousands of other patients, whether a treatment is likely to work and what works best for that patient based on their individual conditions.  
No two of you in this room or, in fact, anywhere in the world are alike.  
But AI models are helping our doctors learn from patients with similar conditions or even similar genetic information and make highly informed decisions about their diagnosis and their treatment options.  
I want to talk about how we are starting to use AI for delivering care to cancer patients.  
Cancer diagnosis can be immensely complicated, both for the doctors in making decisions about diagnosing a primary or secondary cancer, as well as for the patients, in understanding the risks and success rates of the treatment options.  
But we are developing AI models that can help streamline this process by taking information from a number of sources.  
This involves feeding an AI model data from the patient’s blood tests, X-ray images of the suspected lesions, as well as genetic information from a tissue biopsy.  
The trained AI model can rapidly consolidate this information and provide highly accurate predictions of the patient's diagnosis, treatment options most likely to succeed, as well as the prognosis.  
Let’s talk about Peter, who is a cancer patient.  
He’s gone through comprehensive clinical assessment, imaging and various other diagnostic workups, but not even the best doctors in town can tell him where his cancer primary site is, meaning he can’t get a treatment specific for his cancer and his chances of surviving another five years is less than ten percent.  
But our team right here in Brisbane has developed a tool using AI and patients’ genetic information that can accurately identify the cancer primary site of Peter, and empower doctors to give Peter a treatment that we know is going to work for him.  
These type of models can be expanded exponentially to predict accurate health care.  
This means using an AI model to understand whether a certain population is more susceptible to a certain disease and whether they would respond more favorablyto certain health care interventions.  
AI is giving us the ability to have a much more refinedand detailed understanding of human health than we’ve ever had before.  
But there is a catch to the immense promise of AI being implemented into routine clinical practice.  
Our existing regulation frameworks aren’t designed for AI software intended for diagnosing, treating or managing the disease, also known as AI-based software as a medical device.  
They are designed for physical medical devices, like surgical implants, or most software that have the same output every time that the patient or clinicians are using them.  
Traditional software are static, in a sense that the developers release a version of a software and, no matter how many times you use it, it would always have the same output for the same data.  
On the other hand, AI software behaves completely differently to most software in health care because of the intrinsic ability to learn and evolve over time, ideally becoming more intelligent as suited to the environment that they’re being used at.  
Our existing regulation frameworks rely on the static and reproducible nature of this software to prove that they are safe to be implemented into routine clinical practice.  
So, our regulatory authorities’ solution has been to lock the learning potential of these algorithms before they are implemented into clinical practice.  
This means that the model can no longer learn from its environment and new data, which limits its potential to improve its functionality or its accuracy, you know, the whole point of AI.  
And, at times, this can even be harmful for the patientsbecause the AI model is no longer trained on the most up-to-date data and can potentially lead to a wrong diagnosis.  
But the good news is that there are emerging regulation frameworks being proposed that, if implemented right, can be a game changer.  
Our regulatory authorities are proposing using more transparent reporting mechanism so that the developers can disclose how their models would learn and evolve over time.  
And this will be combined with ongoing and real-time monitoring to make sure that the predicted changes actually occur and that the software is adaptive to make much more accurate predictions and improve health care outcomes.  
We also need to make sure that the training data used for these algorithms are representative of the entire human population.  
Let’s look at a mobile-based diagnostic software that we are developing right here in Brisbane that uses AI to detect skin cancer from the images that you’ve taken on your iPhone.  
If this model has been trained on a predominantly Caucasian population, how well do you think it would doon an African American or an Asian patient?  
Our AI developers have a huge responsibility to make sure that data bias doesn’t exist and that their models are trained on diverse and robust data sets, representative of the entire population, you know, not just white males.  
But at times, we understand that this is not entirely possible.  
Skin cancer does, in fact, disproportionately affect the Caucasian population because of the genetic differences, and, as a result, there are much larger data sets available for those patients.  
But this means that we need to build in a functionality in our AI models that, for low confidence results, for an Asian patient, for example, the model is capable of saying “I don’t know” or that “This is my best guess based on a skewed training population.” But, unfortunately, this functionality doesn’t exist yet, and it’s urgently needed to be mandated by our regulators.  
To successfully implement AI in health care, we need to establish new regulatory frameworks in consultation with AI developers, health care practitioners, policy advisers, as well as the patients themselves, to bring the best out of AI.  
Improve the regulatory frameworks can make sure that diverse and robust tools are developed that are compliant and adaptive and can serve the whole population equally.  
If we get this right, we can transform the delivery of health care where we are promoting personalized health and well-being advice.  
I’m excited to be at the forefront of translating this amazing technology into health care and use this to help millions of lives around the world.


## Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/7ZsyYCZB3Nw?si=iku0J4F0SP82JE1n" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#### Transcript
Transcriber: D J
Reviewer: Manlin Fang Ten years ago, I found myself
in the office of a singular individual, 
Dr. John Perlin. At the time, he was 
the chief medical officer for a hospital company 
called HCA healthcare, where I was applying for a
job as a data scientist. and I said to him, 
Dr. Perlin, what is it that you’d have me, 
a data guy, do for you? And he proceeded to tell me 
about a disease called sepsis. It’s a systemic bloodstream infection, 
that if identified early, can be very readily treated with about
$0.25 worth of antibiotics and fluid. But if it goes unrecognized,
Spreads through the body, leading to systemic inflammation, organ
failure, and all too frequently, death. And Doctor Perlin 
proceeded to tell me at length about the etiology, biochemistry,
pharmacology of this disease. And I understood none of
what he was telling me. And I said, John, I really don’t understand, 
I’m not that kind of doctor. I'm a doctor of numbers. And
he said, I understand. I tell you all this to convince
you that as clinicians, we’ve tried everything we can do
in the fight against sepsis, and we are still losing. Our care simply does not arrive 
in time to be relevant. We need an early warning of sepsis. We believe it’s in the data, and that you and your fellow data scientists
can find it. Well, what Dr. Perlin didn’t know, was that 20 years prior 
to that conversation, sepsis had killed my father. He was 58 and I was a teenager, so I found
myself in a room opposite a man, telling me that for want of $0.25 worth
of drugs, my dad might still be alive. And moreover, that I could play a part in preventing other families going
through what I did and my family did. I entered that office seeking a job, 
and I left carrying a mission. But what little did I know. 
You see, healthcare itself is sick. Something is very, very
wrong in health care. You see, we've never had more
well-educated, more dedicated, more specialized physicians. We’ve never had instruments, and labs, and diagnostic tools that
are more precise. We’ve never had therapies and
drugs that are more potent, and can render what 
was once a death sentence, as a mere inconvenience or meme. And yet, despite all of this, healthcare is failing on 
any measure that we care about, be it clinical quality,
patient experience, and most of all, the $4.5 trillion bill that healthcare
levies on America every year. Things are getting worse. But why? People
tell me, “Edmund, it’s complicated.” No, It’s complexity. In healthcare, we 
have never slain the demon of complexity. You see, in other parts of the economy,
like technology or consumer goods, there are patterns and modes of thought
like standardization, automation, playbooks that enable us 
to simplify what we’re doing, by doing the same thing 
over and over again. My Apple Watch is a great example of this. A tremendously complicated device, and yet one of millions
of identical devices. That standardization enables Apple
to make the device at low cost and high quality. But in healthcare,
we are the product, and there's no such thing
as a standard human. Heck, I don't even know what size
my shoe is half the time. And so everything we’ve learned
and applied in the rest of the economy, about simplification, 
doesn’t work in healthcare, and the cruel irony, is that those new 
specializations of physicians, those new instruments, 
those new therapies, while individually good, combine to increase complexity, 
and so make things worse. It’s a pure torture. What we need, is a new mode 
of thought to simplify. We need new technology. And that technology is AI. What is it? An AI is simply a machine that thinks
like a human, but at scale. The first generation of AIs were AIs 
that could do logic, as you and I do. There were enormous branches,
trees of if-then-else statements, inductive and abductive logic. And they worked. But they were incredibly intricate,
expensive to produce, and even more expensive to maintain, and so they fell into disuse. They were the first and the
second AI boom bust cycle. The second generation of AIs
were AIs that can do mathematics and see patterns as we do Share with data, the AI through
machine learning, can infer a model which makes 
predictions about the future. You know, we used to joke 
about the weatherman and how useless and unreliable they were, 
and we don’t anymore, because aided by AI, they are really damn good, they are. The third and current generation of AIs are machines that understand 
language as we do. Catchers
gave great examples of that. These are machines that can
read and write, listen, and speak, in all of our human languages, 
but at scale and,  as a society, we haven’t yet figured out exactly 
what we’re going to do with all of this but we know it's big. One of the leading
proponents is a company called OpenAI, last valued at $80 billion on revenues
of one and losses of 5 billion. And what is it? It's a text box. But it’s a text box, critically, that
contains the whole internet. You see, OpenAI has a machine
that has read the internet, and will answer 
all of your questions about it. And that a text box containing
the internet should be worth an unfathomable sum, should
come as no surprise, because that is precisely, exactly what
Google was for the last generation of AIs Moreover, it's a pattern of thought. OpenAI did not seek to
simplify the internet. They wrapped it in a very simple surface.
That text box, they took the internet can of worms, 
and they put the can around it And that mode of wrapping complexity 
is what we need in healthcare. I’ll give some examples.
My friend David. He's a primary care physician, one of the most mission centred and
hard working people I've ever met. He used to see between 20 and 30 
patients a day in his practice and then he would go to his computer, 
and write notes, about all of those interactions, into the electronic medical record. Those notes feed the leviathan
of healthcare Administration. All of the revenue cycle, 
insurance claims, billing, government compliance, regulation, legal disputes, quality,
everything comes from those notes. Now, David has an AI. 
It’s on his phone and sits on the table while he's consulting
with his patients. It listens to their interaction and
then writes the notes for him. A machine that listens and writes. What it does is it wraps that whole
administrative complexity for him in an interface so simple 
it seems invisible. Aided by this AI, David now sees between
60 and 70 patients a day, an unimaginable increase in his
productivity and decrease in the cost that his patients experience. Now, David may be Superman,
but he's only one man. Can we apply the same logic to clinical
teams or whole hospitals? You know, a hospital is about the most
profound place in modern American life. Most of us came into this
life in a hospital, and most of us will depart from one. And with all of the 
ambulances and helicopters arriving with gunshot
victims and trauma victims, babies being born, 
hearts being transplanted. The complexity is overwhelming. It's more than anybody can
hold in their mind, but it’s not more than an AI can hold. Imagine an AI wrapping the hospital, 
aware of the status of all of the patients, their journey,
and inferring the next best actions for all the clinicians and workers
in the hospital, and sharing it with them in their language. Coordinating that care, wrapping that
hospital administration for the providers will dramatically
reduce their complexity and increase their quality
and productivity. A small example of this is the sepsis
work I described earlier. HCA brought together teams of
clinicians and engineers, and I was privileged to be one of them. Together, we wrapped the subtle complexity
of sepsis development in an algorithm and a workflow, giving clinicians hours of advance
warning of sepsis. And with that tool, they're able to
save thousands of lives a year. There was a lifetime privilege 
to be on those teams Machines that can read and write
give us new opportunities Consider the case of Martha mills. She was a British teenager who,
on a vacation with her family, slipped on her bicycle and jabbed herself
in the abdomen with the handlebars. The pain was intense. She went to
the E.R. it didn't get better, and she was admitted. 
She deteriorated over the weekend, and ultimately succumbed to death. It was a tragedy, an avoidable
tragedy because the signs and symptoms of sepsis were
all over that chart. But they were missed in the clinical and all too human complexity
of modern medicine. Now imagine an AI that has read
the medical textbooks, has read the clinical literature, and is connected to those charts
in real time and can read them. Such an AI would know about sepsis
and would not miss it. Most excitingly, imagine that
AI exists outside of the traditional healthcare system, allied
and aligned to Martha's family, who were at her bedside disempowered
through this whole experience. Such an AI could have told them Martha
is critically deathly ill and needs to be in a pediatric
ICU right now. Here's why. Armed with that information, her parents would have advocated for her
transfer and probably life saving care. All of that technology 
is available today. So what ails us 
in healthcare, is complexity. And the bitter irony, as I said, is that every attempt we make to improve
matters with better tools, with better therapy, with better drugs, makes things worse 
by adding to complexity. We need to simplify. We can't simplify by standardizing.
So we must simplify by wrapping. And I’ve shown how we can wrap
administration for a single physician, hospital operations for 
clinical teams in hospitals. But most of all, I want you 
to leave knowing that AI can wrap the experience of healthcare for
you and for me as consumers, empowering us as advocates, knowers and deciders in our care,
and in the care of those we love. Thank you 




## Project idea

Analyzing different types of medical images to assist doctors in detecting and diagnosing diseases. **AI-powered medical image diagnosis system** that analyzes **X-rays, MRIs, CT scans, and skin images** to detect diseases. Using **deep learning (CNNs)** and **computer vision**, it provides real-time diagnostic insights with heatmaps for explainability. The system features a **user-friendly web interface** and integrates with hospital **EHR systems** to enhance workflow efficiency. By improving accuracy and reducing diagnostic time, MediScan AI supports doctors in **early disease detection and clinical decision-making**.

## Use Cases

1.  **Radiology (X-rays & CT Scans) – Detecting Bone & Chest Diseases**
	- Detect fractures, pneumonia, tuberculosis, and lung diseases.
	- Identify bone abnormalities (osteoporosis, arthritis).
**Datasets:** 
	  Chest x-ray: https://paperswithcode.com/dataset/chestx-ray14
	  Pneumonia dataset: https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge
	  MURA Dataset for bone fracture: https://stanfordmlgroup.github.io/competitions/mura/

1. **Dermatology (Skin Images) – Detecting Skin Diseases**
	 Dermoscopy images (high-resolution images of skin)  
	**Use Cases:**  
	- Detect **skin cancer (melanoma, carcinoma), infections, rashes, or acne**.  
	- Detect common skin conditions such as scabies, etc.
	- Useful for **early detection of malignant melanoma**.
	
	 **Datasets:**  
	 ISIC 2020 Dataset – https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge
	 Derm7pt Dataset – https://github.com/jeremykawahara/derm7pt
	 HAM10000 – https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000

2.  **Cardiology (Echocardiography & ECG Images) – Detecting Heart Diseases**

- **Images to Analyze:** Echocardiograms, Electrocardiograms (ECG)  
 **Use Cases:**  
- Detect **heart valve diseases, arrhythmias, and cardiomyopathy**.  
- AI models help in **automated interpretation of heart conditions**.

**Dataset**
 PhysioNet ECG Dataset – ECG signals with labeled cardiac diseases. https://physionet.org/content/?topic=ecg  
 EchoNet-Dynamic – Echocardiography dataset for heart function analysis.  
 MIT-BIH Arrhythmia Database – https://www.physionet.org/content/mitdb/1.0.0/


1. Knowledge Base: Foundations of AI-Driven Diagnosis

Core Principles

The system leverages core AI and medical imaging principles, utilizing deep learning algorithms for image analysis.

Technology Stack

The technology stack includes Python, TensorFlow/PyTorch, and cloud infrastructure AWS, GCP.

Datasets

The system is trained on various datasets, including chest X-rays, MRI scans, and CT scans.

Example: Pneumonia Detection

ResNet-50 achieves 92% accuracy in pneumonia detection, highlighting the potential of AI in medical diagnosis.