#FYDP #project 


>[!Ideas]
>- Suggesting the most likely condition, with the other conditions that also might occur to the patient.


<iframe width="560" height="315" src="https://www.youtube.com/embed/3PbEgLw6lJ0?si=BkUuyWVFoZmiqkcz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Et5HC8SR0BA?si=__-vSN0V_W15GHkL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
## video
<iframe width="560" height="315" src="https://www.youtube.com/embed/uvqDTbusdUU?si=3rgDsbtTbN__Kjwc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#### **Transcript:**
 Artificial intelligence has often been depicted as villain robots ready to take over the world.  
But I’m here to tell you that AI can actually save lives and improve health care for millions of patients around the world.  
AI is helping us personalize the delivery of care, make hospitals more efficient, and improve access to health care by providing accurate decision-making tools.  
AI is the process of educating a computer model using complex and large data sets.  
The model learns from this data in a training process to build its ability to make decisions or predict outcomes when presented with new data.  
We are talking about having access to a computer model that knows, based on the experience of thousands of other patients, whether a treatment is likely to work and what works best for that patient based on their individual conditions.  
No two of you in this room or, in fact, anywhere in the world are alike.  
But AI models are helping our doctors learn from patients with similar conditions or even similar genetic information and make highly informed decisions about their diagnosis and their treatment options.  
I want to talk about how we are starting to use AI for delivering care to cancer patients.  
Cancer diagnosis can be immensely complicated, both for the doctors in making decisions about diagnosing a primary or secondary cancer, as well as for the patients, in understanding the risks and success rates of the treatment options.  
But we are developing AI models that can help streamline this process by taking information from a number of sources.  
This involves feeding an AI model data from the patient’s blood tests, X-ray images of the suspected lesions, as well as genetic information from a tissue biopsy.  
The trained AI model can rapidly consolidate this information and provide highly accurate predictions of the patient's diagnosis, treatment options most likely to succeed, as well as the prognosis.  
Let’s talk about Peter, who is a cancer patient.  
He’s gone through comprehensive clinical assessment, imaging and various other diagnostic workups, but not even the best doctors in town can tell him where his cancer primary site is, meaning he can’t get a treatment specific for his cancer and his chances of surviving another five years is less than ten percent.  
But our team right here in Brisbane has developed a tool using AI and patients’ genetic information that can accurately identify the cancer primary site of Peter, and empower doctors to give Peter a treatment that we know is going to work for him.  
These type of models can be expanded exponentially to predict accurate health care.  
This means using an AI model to understand whether a certain population is more susceptible to a certain disease and whether they would respond more favorablyto certain health care interventions.  
AI is giving us the ability to have a much more refinedand detailed understanding of human health than we’ve ever had before.  
But there is a catch to the immense promise of AI being implemented into routine clinical practice.  
Our existing regulation frameworks aren’t designed for AI software intended for diagnosing, treating or managing the disease, also known as AI-based software as a medical device.  
They are designed for physical medical devices, like surgical implants, or most software that have the same output every time that the patient or clinicians are using them.  
Traditional software are static, in a sense that the developers release a version of a software and, no matter how many times you use it, it would always have the same output for the same data.  
On the other hand, AI software behaves completely differently to most software in health care because of the intrinsic ability to learn and evolve over time, ideally becoming more intelligent as suited to the environment that they’re being used at.  
Our existing regulation frameworks rely on the static and reproducible nature of this software to prove that they are safe to be implemented into routine clinical practice.  
So, our regulatory authorities’ solution has been to lock the learning potential of these algorithms before they are implemented into clinical practice.  
This means that the model can no longer learn from its environment and new data, which limits its potential to improve its functionality or its accuracy, you know, the whole point of AI.  
And, at times, this can even be harmful for the patientsbecause the AI model is no longer trained on the most up-to-date data and can potentially lead to a wrong diagnosis.  
But the good news is that there are emerging regulation frameworks being proposed that, if implemented right, can be a game changer.  
Our regulatory authorities are proposing using more transparent reporting mechanism so that the developers can disclose how their models would learn and evolve over time.  
And this will be combined with ongoing and real-time monitoring to make sure that the predicted changes actually occur and that the software is adaptive to make much more accurate predictions and improve health care outcomes.  
We also need to make sure that the training data used for these algorithms are representative of the entire human population.  
Let’s look at a mobile-based diagnostic software that we are developing right here in Brisbane that uses AI to detect skin cancer from the images that you’ve taken on your iPhone.  
If this model has been trained on a predominantly Caucasian population, how well do you think it would doon an African American or an Asian patient?  
Our AI developers have a huge responsibility to make sure that data bias doesn’t exist and that their models are trained on diverse and robust data sets, representative of the entire population, you know, not just white males.  
But at times, we understand that this is not entirely possible.  
Skin cancer does, in fact, disproportionately affect the Caucasian population because of the genetic differences, and, as a result, there are much larger data sets available for those patients.  
But this means that we need to build in a functionality in our AI models that, for low confidence results, for an Asian patient, for example, the model is capable of saying “I don’t know” or that “This is my best guess based on a skewed training population.” But, unfortunately, this functionality doesn’t exist yet, and it’s urgently needed to be mandated by our regulators.  
To successfully implement AI in health care, we need to establish new regulatory frameworks in consultation with AI developers, health care practitioners, policy advisers, as well as the patients themselves, to bring the best out of AI.  
Improve the regulatory frameworks can make sure that diverse and robust tools are developed that are compliant and adaptive and can serve the whole population equally.  
If we get this right, we can transform the delivery of health care where we are promoting personalized health and well-being advice.  
I’m excited to be at the forefront of translating this amazing technology into health care and use this to help millions of lives around the world.


## Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/7ZsyYCZB3Nw?si=iku0J4F0SP82JE1n" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#### Transcript
Transcriber: D J
Reviewer: Manlin Fang Ten years ago, I found myself
in the office of a singular individual, 
Dr. John Perlin. At the time, he was 
the chief medical officer for a hospital company 
called HCA healthcare, where I was applying for a
job as a data scientist. and I said to him, 
Dr. Perlin, what is it that you’d have me, 
a data guy, do for you? And he proceeded to tell me 
about a disease called sepsis. It’s a systemic bloodstream infection, 
that if identified early, can be very readily treated with about
$0.25 worth of antibiotics and fluid. But if it goes unrecognized,
Spreads through the body, leading to systemic inflammation, organ
failure, and all too frequently, death. And Doctor Perlin 
proceeded to tell me at length about the etiology, biochemistry,
pharmacology of this disease. And I understood none of
what he was telling me. And I said, John, I really don’t understand, 
I’m not that kind of doctor. I'm a doctor of numbers. And
he said, I understand. I tell you all this to convince
you that as clinicians, we’ve tried everything we can do
in the fight against sepsis, and we are still losing. Our care simply does not arrive 
in time to be relevant. We need an early warning of sepsis. We believe it’s in the data, and that you and your fellow data scientists
can find it. Well, what Dr. Perlin didn’t know, was that 20 years prior 
to that conversation, sepsis had killed my father. He was 58 and I was a teenager, so I found
myself in a room opposite a man, telling me that for want of $0.25 worth
of drugs, my dad might still be alive. And moreover, that I could play a part in preventing other families going
through what I did and my family did. I entered that office seeking a job, 
and I left carrying a mission. But what little did I know. 
You see, healthcare itself is sick. Something is very, very
wrong in health care. You see, we've never had more
well-educated, more dedicated, more specialized physicians. We’ve never had instruments, and labs, and diagnostic tools that
are more precise. We’ve never had therapies and
drugs that are more potent, and can render what 
was once a death sentence, as a mere inconvenience or meme. And yet, despite all of this, healthcare is failing on 
any measure that we care about, be it clinical quality,
patient experience, and most of all, the $4.5 trillion bill that healthcare
levies on America every year. Things are getting worse. But why? People
tell me, “Edmund, it’s complicated.” No, It’s complexity. In healthcare, we 
have never slain the demon of complexity. You see, in other parts of the economy,
like technology or consumer goods, there are patterns and modes of thought
like standardization, automation, playbooks that enable us 
to simplify what we’re doing, by doing the same thing 
over and over again. My Apple Watch is a great example of this. A tremendously complicated device, and yet one of millions
of identical devices. That standardization enables Apple
to make the device at low cost and high quality. But in healthcare,
we are the product, and there's no such thing
as a standard human. Heck, I don't even know what size
my shoe is half the time. And so everything we’ve learned
and applied in the rest of the economy, about simplification, 
doesn’t work in healthcare, and the cruel irony, is that those new 
specializations of physicians, those new instruments, 
those new therapies, while individually good, combine to increase complexity, 
and so make things worse. It’s a pure torture. What we need, is a new mode 
of thought to simplify. We need new technology. And that technology is AI. What is it? An AI is simply a machine that thinks
like a human, but at scale. The first generation of AIs were AIs 
that could do logic, as you and I do. There were enormous branches,
trees of if-then-else statements, inductive and abductive logic. And they worked. But they were incredibly intricate,
expensive to produce, and even more expensive to maintain, and so they fell into disuse. They were the first and the
second AI boom bust cycle. The second generation of AIs
were AIs that can do mathematics and see patterns as we do Share with data, the AI through
machine learning, can infer a model which makes 
predictions about the future. You know, we used to joke 
about the weatherman and how useless and unreliable they were, 
and we don’t anymore, because aided by AI, they are really damn good, they are. The third and current generation of AIs are machines that understand 
language as we do. Catchers
gave great examples of that. These are machines that can
read and write, listen, and speak, in all of our human languages, 
but at scale and,  as a society, we haven’t yet figured out exactly 
what we’re going to do with all of this but we know it's big. One of the leading
proponents is a company called OpenAI, last valued at $80 billion on revenues
of one and losses of 5 billion. And what is it? It's a text box. But it’s a text box, critically, that
contains the whole internet. You see, OpenAI has a machine
that has read the internet, and will answer 
all of your questions about it. And that a text box containing
the internet should be worth an unfathomable sum, should
come as no surprise, because that is precisely, exactly what
Google was for the last generation of AIs Moreover, it's a pattern of thought. OpenAI did not seek to
simplify the internet. They wrapped it in a very simple surface.
That text box, they took the internet can of worms, 
and they put the can around it And that mode of wrapping complexity 
is what we need in healthcare. I’ll give some examples.
My friend David. He's a primary care physician, one of the most mission centred and
hard working people I've ever met. He used to see between 20 and 30 
patients a day in his practice and then he would go to his computer, 
and write notes, about all of those interactions, into the electronic medical record. Those notes feed the leviathan
of healthcare Administration. All of the revenue cycle, 
insurance claims, billing, government compliance, regulation, legal disputes, quality,
everything comes from those notes. Now, David has an AI. 
It’s on his phone and sits on the table while he's consulting
with his patients. It listens to their interaction and
then writes the notes for him. A machine that listens and writes. What it does is it wraps that whole
administrative complexity for him in an interface so simple 
it seems invisible. Aided by this AI, David now sees between
60 and 70 patients a day, an unimaginable increase in his
productivity and decrease in the cost that his patients experience. Now, David may be Superman,
but he's only one man. Can we apply the same logic to clinical
teams or whole hospitals? You know, a hospital is about the most
profound place in modern American life. Most of us came into this
life in a hospital, and most of us will depart from one. And with all of the 
ambulances and helicopters arriving with gunshot
victims and trauma victims, babies being born, 
hearts being transplanted. The complexity is overwhelming. It's more than anybody can
hold in their mind, but it’s not more than an AI can hold. Imagine an AI wrapping the hospital, 
aware of the status of all of the patients, their journey,
and inferring the next best actions for all the clinicians and workers
in the hospital, and sharing it with them in their language. Coordinating that care, wrapping that
hospital administration for the providers will dramatically
reduce their complexity and increase their quality
and productivity. A small example of this is the sepsis
work I described earlier. HCA brought together teams of
clinicians and engineers, and I was privileged to be one of them. Together, we wrapped the subtle complexity
of sepsis development in an algorithm and a workflow, giving clinicians hours of advance
warning of sepsis. And with that tool, they're able to
save thousands of lives a year. There was a lifetime privilege 
to be on those teams Machines that can read and write
give us new opportunities Consider the case of Martha mills. She was a British teenager who,
on a vacation with her family, slipped on her bicycle and jabbed herself
in the abdomen with the handlebars. The pain was intense. She went to
the E.R. it didn't get better, and she was admitted. 
She deteriorated over the weekend, and ultimately succumbed to death. It was a tragedy, an avoidable
tragedy because the signs and symptoms of sepsis were
all over that chart. But they were missed in the clinical and all too human complexity
of modern medicine. Now imagine an AI that has read
the medical textbooks, has read the clinical literature, and is connected to those charts
in real time and can read them. Such an AI would know about sepsis
and would not miss it. Most excitingly, imagine that
AI exists outside of the traditional healthcare system, allied
and aligned to Martha's family, who were at her bedside disempowered
through this whole experience. Such an AI could have told them Martha
is critically deathly ill and needs to be in a pediatric
ICU right now. Here's why. Armed with that information, her parents would have advocated for her
transfer and probably life saving care. All of that technology 
is available today. So what ails us 
in healthcare, is complexity. And the bitter irony, as I said, is that every attempt we make to improve
matters with better tools, with better therapy, with better drugs, makes things worse 
by adding to complexity. We need to simplify. We can't simplify by standardizing.
So we must simplify by wrapping. And I’ve shown how we can wrap
administration for a single physician, hospital operations for 
clinical teams in hospitals. But most of all, I want you 
to leave knowing that AI can wrap the experience of healthcare for
you and for me as consumers, empowering us as advocates, knowers and deciders in our care,
and in the care of those we love. Thank you 




## Project idea

Analyzing different types of medical images to assist doctors in detecting and diagnosing diseases. **AI-powered medical image diagnosis system** that analyzes **X-rays, MRIs, CT scans, and skin images** to detect diseases. Using **deep learning (CNNs)** and **computer vision**, it provides real-time diagnostic insights with heatmaps for explainability. The system features a **user-friendly web interface** and integrates with hospital **EHR systems** to enhance workflow efficiency. By improving accuracy and reducing diagnostic time, MediScan AI supports doctors in **early disease detection and clinical decision-making**.

## Use Cases

1.  **Radiology (X-rays & CT Scans) – Detecting Bone & Chest Diseases**
	- Detect fractures, pneumonia, tuberculosis, and lung diseases.
	- Identify bone abnormalities (osteoporosis, arthritis).
**Datasets:** 
	  Chest x-ray: https://paperswithcode.com/dataset/chestx-ray14
	  Pneumonia dataset: https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge
	  MURA Dataset for bone fracture: https://stanfordmlgroup.github.io/competitions/mura/

1. **Dermatology (Skin Images) – Detecting Skin Diseases**
	 Dermoscopy images (high-resolution images of skin)  
	**Use Cases:**  
	- Detect **skin cancer (melanoma, carcinoma), infections, rashes, or acne**.  
	- Detect common skin conditions such as scabies, etc.
	- Useful for **early detection of malignant melanoma**.
	
	 **Datasets:**  
	 ISIC 2020 Dataset – https://www.kaggle.com/competitions/rsna-pneumonia-detection-challenge
	 Derm7pt Dataset – https://github.com/jeremykawahara/derm7pt
	 HAM10000 – https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000

2.  **Cardiology (Echocardiography & ECG Images) – Detecting Heart Diseases**

- **Images to Analyze:** Echocardiograms, Electrocardiograms (ECG)  
 **Use Cases:**  
- Detect **heart valve diseases, arrhythmias, and cardiomyopathy**.  
- AI models help in **automated interpretation of heart conditions**.

**Dataset**
 PhysioNet ECG Dataset – ECG signals with labeled cardiac diseases. https://physionet.org/content/?topic=ecg  
 EchoNet-Dynamic – Echocardiography dataset for heart function analysis.  
 MIT-BIH Arrhythmia Database – https://www.physionet.org/content/mitdb/1.0.0/
